{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, \"/local/path/to/scripts\")\n",
    "\n",
    "from plotting_utils import palettes, split_on_capitals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File S1 – Sample metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2132 = pd.read_csv(\"../data/metadata_2132.csv\", index_col=0)\n",
    "df_1454 = pd.read_csv(\"../data/metadata_1454_cluster_labels.csv\", index_col=0, dtype={\"sourmash_k_10_1487_25m\": str, \"IHO_Sea_MRGID\": str})\n",
    "df_1454[\"in_final_analysis\"] = True\n",
    "df_2132 = df_2132.join(df_1454[[\"sourmash_k_10_1487_25m\", \"in_final_analysis\"]])\n",
    "df_2132[\"in_final_analysis\"] = df_2132[\"in_final_analysis\"].apply(lambda x: True if x == x else False)\n",
    "df_2132[\"sourmash_k_10_1487_25m\"] = df_2132[\"sourmash_k_10_1487_25m\"].apply(lambda x: x if x == x else False)\n",
    "prov_metadata = palettes[\"k_10\"]\n",
    "prov_metadata = {str(k): v for k, v in prov_metadata.items()}\n",
    "prov_metadata[False] = {\"label\": \"-\", \"description\": \"-\"}\n",
    "prov_labels = {k: v[\"label\"] for k, v in prov_metadata.items()}\n",
    "prov_description = {k: v[\"description\"] for k, v in prov_metadata.items()}\n",
    "df_2132[\"Proposed province description\"] = df_2132[\"sourmash_k_10_1487_25m\"].map(prov_description)\n",
    "df_2132[\"sourmash_k_10_1487_25m\"] = df_2132[\"sourmash_k_10_1487_25m\"].map(prov_labels)\n",
    "prov_category = {\n",
    "    \"BPRL\": \"Polar\",\n",
    "    \"BALT\": \"-\",\n",
    "    \"CTEM\": \"Temperate\",\n",
    "    \"OTEM\": \"Temperate\",\n",
    "    \"STEM\": \"Temperate\",\n",
    "    \"MTEM\": \"Temperate\",\n",
    "    \"TGYR\": \"Tropical\",\n",
    "    \"TRHI\": \"Tropical\",\n",
    "    \"TRLO\": \"Tropical\",\n",
    "    \"APLR\": \"Polar\"\n",
    "}\n",
    "df_2132[\"Proposed province category\"] = df_2132[\"sourmash_k_10_1487_25m\"].map(prov_description)\n",
    "\n",
    "rename_dict = {\n",
    "    \"Prov\": \"Longhurst province code\",\n",
    "    \"ProvDescr\": \"Longhurst province description\",\n",
    "    \"ProvCategory\": \"Longhurst province category\",\n",
    "    \"sourmash_k_10_1487_25m\": \"Proposed province code\",\n",
    "    \"IHO_Sea_fmt\": \"IHO Sea formatted\",\n",
    "    \"sample_name\": \"Sample name\",\n",
    "    \"sra_run\": \"SRA run\",\n",
    "    \"division\": \"Division\",\n",
    "    \"subdivision\": \"Subdivision\",\n",
    "    \"bioproject\": \"BioProject\",\n",
    "    \"biosample\": \"BioSample\",\n",
    "    \"in_final_analysis\": \"Included in final analysis\",\n",
    "}\n",
    "\n",
    "cols_to_remove = [\n",
    "    \"sra_run_fmt\",\n",
    "    \"temperature\",\n",
    "    \"station_fmt\",\n",
    "    \"station\",\n",
    "    \"coords\"\n",
    "]\n",
    "\n",
    "df_2132 = df_2132.rename(columns=rename_dict).drop(columns=cols_to_remove)\n",
    "\n",
    "df_2132.columns = [i.replace(\"_\", \" \") for i in df_2132.columns]\n",
    "env_cols = ['DiffuseAttenuationCoefficientPAR', 'MixedLayerDepth',\n",
    "            'Salinity', 'Terrain', 'Nitrate', 'OceanTemperature',\n",
    "            'DissolvedMolecularOxygen', 'PhotosyntheticallyAvailableRadiation',\n",
    "            'Silicate', 'TotalCloudFraction', 'pH', 'SeaIceThickness',\n",
    "            'SeaWaterSpeed', 'DissolvedIron', 'Phosphate', 'AirTemperature',\n",
    "            'TotalPhytoplankton', 'SeaIceCover', 'Chlorophyll']\n",
    "\n",
    "accession_cols = ['Sample name', 'SRA run', 'Division', 'Subdivision', 'BioProject',\n",
    "                  'BioSample']\n",
    "\n",
    "sample_cols = [\"latitude\", \"longitude\", \"collection date\", \"depth\", \"instrument\"]\n",
    "\n",
    "category_cols = ['Proposed province code', 'Proposed province description', 'Proposed province category', 'Longhurst province code', 'Longhurst province description', 'Longhurst province category', 'IHO Sea', 'IHO Sea formatted', 'IHO Sea MRGID', 'Included in final analysis']\n",
    "\n",
    "rename_env = {k: v.replace(\"P A R\", \"PAR\") for k,v in dict(zip(env_cols, [split_on_capitals(i) for i in env_cols])).items()}\n",
    "rename_sample = dict(zip(sample_cols, [i.capitalize() for i in sample_cols]))\n",
    "\n",
    "df_2132 = df_2132.rename(columns={**rename_env, **rename_sample})\n",
    "\n",
    "env_cols = [rename_env.get(i, i) for i in env_cols]\n",
    "sample_cols = [rename_sample.get(i, i) for i in sample_cols]\n",
    "\n",
    "df_2132 = df_2132[accession_cols + category_cols + sample_cols + env_cols]\n",
    "df_2132[\"Proposed province code\"] = pd.Categorical(df_2132[\"Proposed province code\"], categories=\"BPLR BALT CTEM SANT NADR MEDI TGYR PEQD TROP APLR\".split(), ordered=True)\n",
    "df_2132 = df_2132.sort_values([\"Included in final analysis\", \"Proposed province code\", \"Latitude\"], ascending=[False, True, False])\n",
    "\n",
    "df_2132[\"Collection date\"] = pd.to_datetime(df_2132[\"Collection date\"], format=\"mixed\", utc=True)\n",
    "df_2132[\"Collection date\"] = df_2132[\"Collection date\"].dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2132.to_excel(\"/local/path/to/data/File_S1_sample_metadata.xlsx\", index=False)\n",
    "df_2132.to_csv(\"/local/path/to/data/File_S1_sample_metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File S2 – Genome metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/local/path/to/data/genome_metadata.tsv\", index_col=0, sep=\"\\t\")\n",
    "df = df.rename_axis(\"Genome ID\")\n",
    "gtdb_columns = ['checkm_marker',\n",
    "       'checkm_n_genome', 'checkm_n_marker', 'checkm_n_marker_set', 'checkm_0',\n",
    "       'checkm_1', 'checkm_2', 'checkm_3', 'checkm_4', 'checkm_5+',\n",
    "       'checkm_compl', 'checkm_contam', 'checkm_hetero', 'genome_quality_QS',\n",
    "       'QS_plus_ln(N50)', 'gtdb_novelty', 'gtdb_classification',\n",
    "       'gtdb_fastani_reference', 'gtdb_fastani_reference_radius',\n",
    "       'gtdb_fastani_taxonomy', 'gtdb_fastani_ani',\n",
    "       'gtdb_closest_placement_radius', 'gtdb_fastani_af',\n",
    "       'gtdb_closest_placement_reference', 'gtdb_closest_placement_taxonomy',\n",
    "       'gtdb_closest_placement_ani', 'gtdb_closest_placement_af',\n",
    "       'gtdb_pplacer_taxonomy', 'gtdb_classification_method', 'gtdb_note',\n",
    "       'gtdb_other_related_references(genome_id,species_name,radius,ANI,AF)',\n",
    "       'gtdb_aa_percent', 'gtdb_translation_table', 'gtdb_red_value',\n",
    "       'gtdb_warnings',]\n",
    "\n",
    "metric_columns = ['num_contig', 'largest_contig_length', 'total_length', 'percent_GC',\n",
    "       'N50', 'ambiguous_nucleotide_per_100kb']\n",
    "\n",
    "    \n",
    "taxonomy_columns = ['data_source', 'genome_type', 'domain',\n",
    "       'phylum', 'class', 'order', 'family', 'genus', 'species',\n",
    "       'sci_names']\n",
    "\n",
    "df.sort_values(taxonomy_columns[2:], ascending=False)\n",
    "print(\"Columns not present:\", [i for i in df.columns if i not in gtdb_columns + metric_columns + taxonomy_columns])\n",
    "df = df[taxonomy_columns + metric_columns + gtdb_columns]\n",
    "\n",
    "df.columns = [i.replace(\"_\", \" \").capitalize() for i in df.columns]\n",
    "\n",
    "replace_terms = {\n",
    "       \"Gtdb\": \"GTDB\",\n",
    "       \"Checkm\": \"CheckM\",\n",
    "       \"gc\": \"GC\",\n",
    "       \"quality qs\": \"quality Qs\",\n",
    "       \"n genome\": \"num genome\",\n",
    "       \"red value\": \"RED value\" \n",
    "}\n",
    "\n",
    "new_cols = {}\n",
    "for term, new_term in replace_terms.items():\n",
    "    for col in df.columns:\n",
    "        if term in col:\n",
    "            new_cols[col] = col.replace(term, new_term)\n",
    "\n",
    "df = df.rename(columns=new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/local/path/to/data/File_S2_genome_metadata.csv\")\n",
    "df.to_excel(\"/local/path/to/data/File_S2_genome_metadata.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
