{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from glob import glob\n",
    "from itertools import cycle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, auc\n",
    "\n",
    "os.environ['PATH'] = os.environ['PATH'] + ':/apps/easybuild-2022/easybuild/software/Compiler/GCC/11.3.0/texlive/20230313/bin/x86_64-linux/'\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "sys.path.insert(0, \"/local/path/to/scripts/\")\n",
    "sys.path.insert(0, \"/local/path/to/scripts/\")\n",
    "from plotting_utils import palettes, split_on_capitals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk with Saritha\n",
    "\n",
    "- Mean and std. dev. of confusion matrix from cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "env_cols = \"Salinity Nitrate OceanTemperature DissolvedMolecularOxygen Silicate pH DissolvedIron Phosphate SeaIceCover Chlorophyll\".split()\n",
    "# env_data_glob_string = \"/local/path/to/data/environmental/*baseline*.nc\"\n",
    "\n",
    "data_dir = \"/local/path/to/\"\n",
    "data_dir = \"/local/path/to/\"\n",
    "\n",
    "smd = pd.read_csv(f\"{data_dir}/provinces_final/data/metadata_1454_cluster_labels.csv\", index_col=0)\n",
    "\n",
    "smd[\"cluster\"] = smd[\"sourmash_k_10_1487_25m\"].map({k: v[\"label\"] for k, v in palettes[\"k_10\"].items()})\n",
    "\n",
    "test_size = 0.5\n",
    "random_state = 100\n",
    "X = smd.drop_duplicates(\"coords\")[env_cols]\n",
    "y = smd.drop_duplicates(\"coords\")[\"sourmash_k_10_1487_25m\"].astype(str)\n",
    "y = smd.drop_duplicates(\"coords\")[\"cluster\"]\n",
    "scaler = StandardScaler()\n",
    "scale = False\n",
    "palette = {v[\"label\"]: v[\"color\"] for k, v in palettes[\"k_10\"].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated Stratified *k*-fold with modified RF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your data in X and y\n",
    "# Define the classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=random_state, max_depth=10, min_samples_split=5, min_samples_leaf=2, max_samples=0.75)\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = RepeatedStratifiedKFold(n_splits=9, n_repeats=10, random_state=random_state)\n",
    "\n",
    "\n",
    "confusion_matrices, accuracies = [], []\n",
    "feature_importances = []\n",
    "for i, (train_index, test_index) in enumerate(cv.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Optionally scale the data\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Fit the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    confusion_matrix_ = confusion_matrix(y_test, y_pred, normalize='pred')\n",
    "    confusion_matrices.append(confusion_matrix_)\n",
    "\n",
    "    # Evaluate the performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Get the feature importances\n",
    "    feature_importances.append(clf.feature_importances_)\n",
    "    print(f\"Fold {i}: Accuracy on the test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(feature_importances)\n",
    "feature_importances.columns = clf.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_order = feature_importances.mean().sort_values(ascending=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X.corr()\n",
    "corr = corr.loc[feature_importances_order, feature_importances_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(10, 16))\n",
    "\n",
    "sns.boxenplot(data=feature_importances[feature_importances_order], palette=\"Blues_r\", orient=\"h\", ax=axs[0])\n",
    "axs[0].set_xlabel(\"Feature relative importance\")\n",
    "axs[0].set_title(\"Feature importance across 100 folds of cross-validation\")\n",
    "sns.heatmap(corr, cmap=\"coolwarm_r\", annot=True, fmt=\".2f\", ax=axs[1])\n",
    "axs[1].set_title(\"Correlation between predictor features\")\n",
    "\n",
    "plt.annotate(\"A\", (0.05, 0.875), xycoords=\"figure fraction\", weight=\"bold\", size=16)\n",
    "plt.annotate(\"B\", (0.05, 0.475), xycoords=\"figure fraction\", weight=\"bold\", size=16)\n",
    "\n",
    "# plt.savefig(\"/local/path/to/figures/final_draft_imgs/fig_S5_feature_importance_correlation.png\", dpi=600, bbox_inches=\"tight\")\n",
    "# plt.savefig(\"/local/path/to/figures/final_draft_imgs/fig_S5_feature_importance_correlation.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaged confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = np.mean(np.stack(confusion_matrices), axis=0)\n",
    "confusion = pd.DataFrame(confusion, index=clf.classes_, columns=clf.classes_)\n",
    "\n",
    "confusion_std = np.std(np.stack(confusion_matrices), axis=0)\n",
    "confusion_std = pd.DataFrame(confusion_std, index=clf.classes_, columns=clf.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the annotation text with an optional diagonal parameter\n",
    "def create_annot_text(mean_df, std_df, diagonal=True):\n",
    "    annot = mean_df.round(2).astype(str)\n",
    "    if diagonal:\n",
    "        for i in range(len(mean_df)):\n",
    "            annot.iloc[i, i] += \" ± \" + str(round(std_df.iloc[i, i], 2))\n",
    "    else:\n",
    "        annot += \" ± \" + std_df.round(2).astype(str)\n",
    "    return annot\n",
    "\n",
    "# Create annotation text\n",
    "annot_text = create_annot_text(confusion, confusion_std)\n",
    "\n",
    "# Build the plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(confusion, annot=annot_text, fmt=\"\", cmap=plt.cm.Blues, linewidths=0.2, ax=ax,\n",
    "            annot_kws={'size': 10})\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = clf.classes_\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "ax.set_xticks(tick_marks2, class_names, rotation=0)\n",
    "ax.set_yticks(tick_marks2, class_names, rotation=0)\n",
    "ax.set_xlabel('Predicted label')\n",
    "ax.set_ylabel('True label')\n",
    "# ax.set_title('Confusion matrix for Random Forest model', loc='left')\n",
    "ax.set_title('Cross-validation strategy: repeated stratified \\\\textit{k}-fold. 9 splits, 10 repeats.\\nRF params: Max._depth=10, Min._samples_split=5, Min._samples_leaf=2, Max._samples=0.7'.replace(\"_\", \" \"), loc='left')\n",
    "\n",
    "outfile = f\"{data_dir}/provinces_final/figures/final_draft_imgs/figS4_confusion_matrix_repeated_kfold.svg\"\n",
    "# plt.savefig(outfile, dpi=\"figure\" if outfile[-3:] != \"png\" else 600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OvR ROC curve – all provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(clf, X_train, y_train, X_test, y_test, classes, ax, binary_clf=False, set_ylabel=True, set_xlabel=True, title='Receiver Operating Characteristic (ROC) - Multiclass'):\n",
    "    clf.fit(X_train, y_train)\n",
    "    clf.classes_ = classes\n",
    "\n",
    "    y_score = clf.predict_proba(X_test) if not binary_clf else clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    if binary_clf:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=clf.classes_[1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        ax.plot(fpr, tpr, color='gray', lw=2, label='ROC curve (area = {0:0.2f})'.format(roc_auc))\n",
    "        ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        ax.set_xlim([-0.01, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        if title:\n",
    "            ax.set_title(title)\n",
    "    else:\n",
    "        for i, class_ in enumerate(classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Compute micro-average ROC curve and ROC area\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "        for i, class_ in enumerate(classes):\n",
    "            ax.plot(fpr[i], tpr[i], color=palette[class_], lw=2,\n",
    "                    label=f'{class_} (area = {round(roc_auc[i], 2)})')\n",
    "\n",
    "        ax.plot(fpr[\"micro\"], tpr[\"micro\"], color='deeppink', linestyle=':', linewidth=4,\n",
    "                label=f\"Micro-average (area = {round(roc_auc['micro'], 2)})\")\n",
    "\n",
    "        ax.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        ax.set_xlim([-0.05, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        if title:\n",
    "            ax.set_title(title)\n",
    "    if set_xlabel:\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "    if set_ylabel:\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "    ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GridSpec with 2 rows and 2 columns\n",
    "fig = plt.figure(figsize=(32, 20))\n",
    "gs = gridspec.GridSpec(3, 2, figure=fig, width_ratios=[2.5, 1], height_ratios=[1, 1, 1], hspace=0.2, wspace=0.1)\n",
    "\n",
    "# Create the axes using add_subplot from GridSpec\n",
    "ax1 = fig.add_subplot(gs[:, 0])  # First plot (top-left)\n",
    "ax2 = fig.add_subplot(gs[0, 1],)  # Second plot (top-right)\n",
    "ax3 = fig.add_subplot(gs[1, 1], sharex=ax2)  # Third plot (bottom-left)\n",
    "ax4 = fig.add_subplot(gs[2, 1], sharex=ax2)  # Fourth plot (bottom-right)\n",
    "\n",
    "# Create annotation text\n",
    "annot_text = create_annot_text(confusion, confusion_std)\n",
    "\n",
    "# Build the plot\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(confusion, annot=annot_text, fmt=\"\", cmap=plt.cm.Blues, linewidths=0.2, ax=ax1,\n",
    "            annot_kws={'size': 15}, cbar=False)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = clf.classes_\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "ax1.set_xticks(tick_marks2, class_names, rotation=0)\n",
    "ax1.set_yticks(tick_marks2, class_names, rotation=0)\n",
    "ax1.set_xlabel('Predicted label')\n",
    "ax1.set_ylabel('True label')\n",
    "ax1.set_title('Cross-validation strategy: repeated stratified \\\\textit{k}-fold. 9 splits, 10 repeats.\\nRF params: Max._depth=10, Min._samples_split=5, Min._samples_leaf=2, Max._samples=0.7'.replace(\"_\", \" \"), loc='left')\n",
    "\n",
    "X_all = smd.drop_duplicates(\"coords\")[env_cols]\n",
    "y_all = smd.drop_duplicates(\"coords\")[\"sourmash_k_10_1487_25m\"].astype(str)\n",
    "y_all = smd.drop_duplicates(\"coords\")[\"cluster\"]\n",
    "\n",
    "# All classes\n",
    "classes_all = np.unique(y_all)\n",
    "y_bin_all = label_binarize(y_all, classes=classes_all)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_bin_all, test_size=test_size, random_state=0, stratify=y\n",
    ")\n",
    "clf_ = OneVsRestClassifier(RandomForestClassifier(n_estimators=100, random_state=random_state))\n",
    "plot_roc_curve(clf_, X_train, y_train, X_test, y_test, classes_all, ax2, set_xlabel=False, set_ylabel=False, title='Receiver Operating Characteristic (ROC) curve – all provinces')\n",
    "\n",
    "# Temperate classes\n",
    "prov_cat_df_temp = smd[smd[\"cluster\"].isin(\"CTEM MTEM STEM OTEM\".split())]\n",
    "X_temp = prov_cat_df_temp.drop_duplicates(\"coords\")[env_cols]\n",
    "y_temp = prov_cat_df_temp.drop_duplicates(\"coords\")[\"sourmash_k_10_1487_25m\"].astype(str)\n",
    "y_temp = prov_cat_df_temp.drop_duplicates(\"coords\")[\"cluster\"]\n",
    "classes_temp = np.unique(y_temp)\n",
    "y_bin_temp = label_binarize(y_temp, classes=classes_temp)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_temp, y_bin_temp, test_size=test_size, random_state=random_state, stratify=y_temp\n",
    ")\n",
    "plot_roc_curve(clf_, X_train, y_train, X_test, y_test, classes_temp, ax3, set_xlabel=False, set_ylabel=False, title='ROC curve – Temperate')\n",
    "\n",
    "# Tropical classes\n",
    "prov_cat_df_trop = smd[smd[\"cluster\"].isin(\"TGYR TRHI TRLO\".split())]\n",
    "X_trop = prov_cat_df_trop.drop_duplicates(\"coords\")[env_cols]\n",
    "y_trop = prov_cat_df_trop.drop_duplicates(\"coords\")[\"sourmash_k_10_1487_25m\"].astype(str)\n",
    "y_trop = prov_cat_df_trop.drop_duplicates(\"coords\")[\"cluster\"]\n",
    "classes_trop = np.unique(y_trop)\n",
    "y_bin_trop = label_binarize(y_trop, classes=classes_trop)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_trop, y_bin_trop, test_size=test_size, random_state=random_state, stratify=y_trop\n",
    ")\n",
    "plot_roc_curve(clf_, X_train, y_train, X_test, y_test, classes_trop, ax4, title='ROC curve – Tropical')\n",
    "\n",
    "ax2.tick_params(labelbottom=False)\n",
    "ax3.tick_params(labelbottom=False)\n",
    "plt.annotate(\"\\\\textbf{A}\", (0.05, 0.81), xycoords=\"figure fraction\", weight=\"bold\", size=24)\n",
    "plt.annotate(\"\\\\textbf{B}\", (0.62, 0.81), xycoords=\"figure fraction\", weight=\"bold\", size=24)\n",
    "\n",
    "# plt.savefig(\"/local/path/to/figures/final_draft_imgs/figS3_confusion_matrix_roc_curve.svg\", bbox_inches=\"tight\")\n",
    "plt.savefig(\"/local/path/to/figures/final_draft_imgs/figS3_confusion_matrix_roc_curve.png\", dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your data in X (pandas DataFrame) and y\n",
    "# Define the base classifier\n",
    "clf_ = RandomForestClassifier(\n",
    "    n_estimators=100, random_state=random_state, \n",
    "    max_depth=10, min_samples_split=5, min_samples_leaf=2, max_samples=0.75\n",
    ")\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = RepeatedStratifiedKFold(n_splits=9, n_repeats=10, random_state=random_state)\n",
    "\n",
    "# Lists to store results\n",
    "confusion_matrices, accuracies = [], []\n",
    "class_feature_importances = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(cv.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Optionally scale the data\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Fit the OneVsRestClassifier\n",
    "    onevsr = OneVsRestClassifier(clf_).fit(X_train, y_train)\n",
    "\n",
    "    # Predict the test set\n",
    "    y_pred = onevsr.predict(X_test)\n",
    "    confusion_matrix_ = confusion_matrix(y_test, y_pred, normalize='pred')\n",
    "    confusion_matrices.append(confusion_matrix_)\n",
    "\n",
    "    # Evaluate the performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    # Get the correctly ordered class labels\n",
    "    ordered_class_labels = onevsr.classes_\n",
    "\n",
    "    # Get feature importances for each class using ordered class labels and feature names\n",
    "    class_importances = {}\n",
    "    for class_index, class_label in enumerate(ordered_class_labels):\n",
    "        # Get feature importances for the class\n",
    "        importances = onevsr.estimators_[class_index].feature_importances_\n",
    "        # Map feature importances to feature names\n",
    "        feature_importances_with_labels = pd.Series(importances, index=X.columns)\n",
    "        class_importances[class_label] = feature_importances_with_labels\n",
    "    class_feature_importances.append(class_importances)\n",
    "    \n",
    "    print(f\"Fold {i}: Accuracy on the test set: {accuracy}\")\n",
    "\n",
    "# After the loop, you can analyze feature importances for each class across folds using correct class labels and feature names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_feature_importances_dict = {class_: pd.DataFrame(pd.DataFrame(class_feature_importances).loc[:, class_].to_list()) for class_ in y.unique()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_, df in class_feature_importances_dict.items():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    sns.boxenplot(data=df, palette=\"Blues_r\", orient=\"h\", ax=ax)\n",
    "    ax.set_title(f\"Feature importance for class {class_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_feature_importances_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances.columns = [split_on_capitals(i) for i in feature_importances.columns]\n",
    "feature_importances_order = [split_on_capitals(i) for i in feature_importances_order]\n",
    "corr.index = [split_on_capitals(i) for i in corr.index]\n",
    "corr.columns = [split_on_capitals(i) for i in corr.columns]\n",
    "for df_ in class_feature_importances_dict.values():\n",
    "    df_.columns = [split_on_capitals(i) for i in df_.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(22.5, 20))\n",
    "\n",
    "# Create a 2-row gridspec\n",
    "gs = fig.add_gridspec(2, 1, height_ratios=[1, 1], hspace=0.225)\n",
    "\n",
    "# First row - divide into 2 equal subplots\n",
    "gs_first_row = gs[0].subgridspec(1, 2, wspace=0.2)  # 1 row, 2 columns\n",
    "ax1 = fig.add_subplot(gs_first_row[0, 0])  # First row, first half\n",
    "ax2 = fig.add_subplot(gs_first_row[0, 1])  # First row, second half\n",
    "\n",
    "# Second gridspec for the second and third rows combined (5 plots each)\n",
    "gs_second_row = gs[1].subgridspec(2, 5)  # 2 rows, 5 columns\n",
    "\n",
    "# Second row - 5 equally wide plots\n",
    "ax3 = fig.add_subplot(gs_second_row[0, 0])\n",
    "ax4 = fig.add_subplot(gs_second_row[0, 1])\n",
    "ax5 = fig.add_subplot(gs_second_row[0, 2])\n",
    "ax6 = fig.add_subplot(gs_second_row[0, 3])\n",
    "ax7 = fig.add_subplot(gs_second_row[0, 4])\n",
    "\n",
    "# Third row - 5 equally wide plots\n",
    "ax8 = fig.add_subplot(gs_second_row[1, 0])\n",
    "ax9 = fig.add_subplot(gs_second_row[1, 1])\n",
    "ax10 = fig.add_subplot(gs_second_row[1, 2])\n",
    "ax11 = fig.add_subplot(gs_second_row[1, 3])\n",
    "ax12 = fig.add_subplot(gs_second_row[1, 4])\n",
    "\n",
    "class_axes = [ax3, ax4, ax5, ax6, ax7, ax8, ax9, ax10, ax11, ax12]\n",
    "\n",
    "sns.heatmap(corr, cmap=\"coolwarm_r\", annot=True, fmt=\".2f\", ax=ax1, cbar=False)\n",
    "ax1.set_title(\"Correlation between predictor features\")\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), fontsize=12)  # Adjust fontsize as needed\n",
    "ax1.xaxis.set_ticklabels(ax1.get_xticklabels(), rotation=45, ha=\"right\", fontsize=10)\n",
    "\n",
    "\n",
    "sns.boxenplot(data=feature_importances[feature_importances_order], palette=\"Blues_r\", orient=\"h\", ax=ax2)\n",
    "ax2.set_xlabel(\"Feature relative importance for classification between all classes\")\n",
    "ax2.set_title(\"Feature importance across 100 folds of cross-validation\")\n",
    "ax2.yaxis.set_ticklabels(ax2.yaxis.get_ticklabels(), fontsize=10)  # Adjust fontsize as needed\n",
    "\n",
    "plt.annotate(\"\\\\textbf{A}\", (0.05, 0.80), xycoords=\"figure fraction\", fontweight=\"bold\", size=16)\n",
    "plt.annotate(\"\\\\textbf{B}\", (0.515, 0.80), xycoords=\"figure fraction\", fontweight=\"bold\", size=16)\n",
    "plt.annotate(\"\\\\textbf{C}\", (0.05, 0.4), xycoords=\"figure fraction\", fontweight=\"bold\", size=16)\n",
    "\n",
    "colour_dict = {v[\"label\"]: v[\"color\"] for k, v in palettes[\"k_10\"].items()}\n",
    "for ax_, (class_, df) in zip(class_axes, class_feature_importances_dict.items()):\n",
    "    if ax_ not in [ax3, ax8]:\n",
    "        ax_.yaxis.set_ticklabels([])\n",
    "    if ax_ is ax10:\n",
    "        ax_.set_xlabel(\"Feature relative importance per class (One vs. Rest classifier)\")\n",
    "    sns.boxenplot(data=df[feature_importances_order], orient=\"h\", ax=ax_, color=colour_dict[class_])\n",
    "    ax_.set_title(class_)\n",
    "\n",
    "plt.savefig(\"/local/path/to/figures/final_draft_imgs/figS4_feature_importance_correlation.svg\", bbox_inches=\"tight\")\n",
    "# plt.savefig(\"/local/path/to/figures/final_draft_imgs/figS4_feature_importance_correlation.png\", dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
